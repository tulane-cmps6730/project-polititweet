## ChatGPT Performance Analysis of Annotation Tasks

Many Natural Language Processing (NLP) applications require labeled data which is both time consuming and expensive. Projects of large scope usually require many manual coders, and niche areas of study require these coders to have a degree of training or knowledge of the field. The advance of Large Language Models (LLMs) in the past decade have led to huge improvements in language processing and comprehension. Chatbots like ChatGPT are capable of outperforming annotators on specific datasets, and their zero-shot accuracy provide compelling evidence that LLMs could be the future of text annotation. This study will be focused on three things: (1) how well does ChatGPT compare to human coders on a multi-class problem, (2) how does it compare against other NLP approaches and (3) with slight prompt engineering and a few pre-training steps, does the ChatGPT approach offer efficiency benefits over the industry standards? 

This project is concerned with the following: 
1. How well do ChatGPTâ€™s zero-shot and fine-tuned models hold up against an NLP model trained on the same task, with the same labeled data? 
2. What forms should prompt-engineering on multi-class classification problems take? 
3. How much fine-tuning can be generalized to an unseen domain?
